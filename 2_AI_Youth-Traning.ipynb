{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ecf381c0-5d16-4464-b63b-5d07e56c5fcb",
   "metadata": {},
   "source": [
    "<img src=\"./images/kisti_logo.jpg\" width=\"100\"> <img src=\"./images/unist_logo.jpg\" width=\"100\"> <img src=\"./images/kisti_mas.png\" width=\"90\"> <img src=\"./images/unist_mas.jpg\" width=\"70\">\n",
    "\n",
    "# **2025년 겨울방학 AI 팀프로젝트 슈퍼컴퓨팅 청소년 캠프**\n",
    "\n",
    "---\n",
    "### **Edge Device를 이용한 AI 실습**\n",
    "### **2. 인공신경망을 이용한 이미지 훈련 및 검증**\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd91bf9d-88fb-4254-8da3-056ff16222e6",
   "metadata": {},
   "source": [
    "**<span style=\"color:red\">과제 시 아래 셀과 [model_definitions.py](./model_definitions.py) 수정 가능</span>**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6986c95d-6b60-4fe7-9c83-ec49028d4fa1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 훈련에 이용할 데이터 설정\n",
    "data_dir = \"./classification_sample/thumbs_A\"\n",
    "\n",
    "# 하이퍼파라미터 설정\n",
    "batch_size = 32\n",
    "learning_rate = 0.001\n",
    "epochs = 10\n",
    "\n",
    "# 출력 모델 이름 설정: 모델 제출 시 \"model_{조번호}.pth\" 로 제출, (예:1조=model_1.pth)\n",
    "model_name = 'model_full.pth'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd2cf98a-358b-403a-82be-f4e53167be42",
   "metadata": {},
   "source": [
    "---\n",
    "### 네크워크에 입력할 문제 정보 확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64039003-9ce8-42f1-825a-9b658b9060e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "#--------------------------------------\n",
    "# 이미지 크기 설정\n",
    "image_width = 320   # 고정!!, 수정 금지\n",
    "image_height = 240  # 고정!!, 수정 금지\n",
    "\n",
    "# 데이터 디렉토리 유효성 검사\n",
    "print('현재 위치:',os.getcwd())  # 현재 작업 디렉토리 출력\n",
    "\n",
    "if not os.path.exists(data_dir):\n",
    "    raise FileNotFoundError(f\"Data directory '{data_dir}' does not exist.\")\n",
    "\n",
    "# 이미지 크기와 채널 설정\n",
    "image_RGB = 3\n",
    "input_size = image_width * image_height * image_RGB\n",
    "\n",
    "# 출력 확인\n",
    "print(f\"입력 크기: {input_size}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2693ec30-fa1f-4363-8a10-556a5f5df8ec",
   "metadata": {},
   "source": [
    "---\n",
    "### 데이터 전처리\n",
    "- 보다 정확한 모델을 만들기 위해 이미지를 전처리 하여 효율적인 모델을 만들 수 있도록 이미지 처리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c4cd278-ec64-42db-93b5-f06649080516",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchvision.transforms as transforms\n",
    "\n",
    "# 데이터 전처리 및 증강 설정\n",
    "use_augmentation = True  # 데이터 증강 여부 설정\n",
    "\n",
    "transform = transforms.Compose([\n",
    "    # 데이터 증강 (필요한 경우 활성화)\n",
    "    transforms.ColorJitter(0.2, 0.2, 0.2, 0.2) if use_augmentation else transforms.Lambda(lambda x: x),\n",
    "    # 이미지 크기 조정\n",
    "    transforms.Resize((image_width, image_height)),\n",
    "    # 텐서 변환\n",
    "    transforms.ToTensor(),\n",
    "    # 정규화 (ImageNet 사전 학습 모델과 호환)\n",
    "    transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58d5a844-6c01-42fc-a7f5-f436ddfc0df2",
   "metadata": {},
   "source": [
    "---\n",
    "### 이미지 데이터 입력 및 처리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae754cea-1612-45d1-b9da-e5ae62562770",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import DataLoader, random_split\n",
    "from torchvision import datasets\n",
    "\n",
    "# 데이터셋 로드\n",
    "dataset = datasets.ImageFolder(root=data_dir, transform=transform)\n",
    "print('전체 이미지 갯수:',len(dataset))\n",
    "\n",
    "# 데이터 디렉토리 내 실제 카테고리 확인\n",
    "actual_category = sorted([d for d in os.listdir(data_dir) if os.path.isdir(os.path.join(data_dir, d))])\n",
    "print(f\"폴더 '{data_dir}' 안에 있는 실제 categories name: {actual_category}\")\n",
    "\n",
    "# 데이터셋 크기와 분할 비율 설정\n",
    "train_ratio = 0.8  # 훈련 데이터 비율\n",
    "torch.manual_seed(42)  # 랜덤 시드 설정\n",
    "train_size = int(train_ratio * len(dataset))\n",
    "val_size = len(dataset) - train_size\n",
    "train_dataset, val_dataset = random_split(dataset, [train_size, val_size])\n",
    "\n",
    "# 데이터 로더 생성\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "# 데이터셋 확인\n",
    "print(f\"훈련 데이터 셋 크기: {len(train_dataset)}\")\n",
    "print(f\"검증 데이터 셋 크기: {len(val_dataset)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "986ef27d-51d3-4fbb-a75c-254ffbb14bde",
   "metadata": {},
   "source": [
    "---\n",
    "### 샘플 이미지 확인을 통한 데이터 확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d049d46-95f7-4f0b-b5e2-f003fe61abbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "from IPython.display import display\n",
    "\n",
    "print(\"클래스 당 하나의 샘플 이미지 출력:\")\n",
    "\n",
    "for category, class_idx in dataset.class_to_idx.items():\n",
    "    # 해당 클래스의 인덱스 필터링\n",
    "    indices = [i for i, (_, label) in enumerate(dataset.samples) if label == class_idx]\n",
    "    \n",
    "    if indices:\n",
    "        # 첫 번째 샘플 경로 가져오기\n",
    "        sample_path, label = dataset.samples[indices[0]]\n",
    "        try:\n",
    "            # PIL을 사용해 이미지를 열고 표시\n",
    "            img = Image.open(sample_path)\n",
    "            print(f\"카테고리: {category}\")\n",
    "            display(img)\n",
    "        except Exception as e:\n",
    "            print(f\"이미지 로드 실패: {sample_path}, 오류: {e}\")\n",
    "    else:\n",
    "        print(f\"클래스 '{category}'와 관련된 샘플 없음!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4830a52c-8a9e-4b75-b845-233ca32f46a5",
   "metadata": {},
   "source": [
    "---\n",
    "### 학습 및 검증 과정 설정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "680d812c-92f1-4983-952b-24cb5ae11252",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 학습 함수 진행 과정\n",
    "def train_one_epoch(model, train_loader, optimizer, criterion):\n",
    "    model.train()  # 학습 모드로 설정\n",
    "    total_loss = 0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "\n",
    "    for images, labels in train_loader:\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "\n",
    "        # 순전파 (Forward)\n",
    "        if images.size(0) == 1:\n",
    "            model.eval()\n",
    "            outputs = model(images)\n",
    "            model.train()\n",
    "        else:\n",
    "            outputs = model(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "\n",
    "        # 역전파 (Backward)\n",
    "        optimizer.zero_grad()  # 이전 그래디언트 초기화\n",
    "        loss.backward()        # 그래디언트 계산\n",
    "\n",
    "        # Gradient clipping (optional)\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)  # gradient 증가 제한으로 급변동 방지\n",
    "\n",
    "        optimizer.step()       # 모델 업데이트\n",
    "\n",
    "        # 손실과 정확도 계산\n",
    "        total_loss += loss.item()\n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "        total += labels.size(0)\n",
    "\n",
    "    accuracy = 100 * correct / total\n",
    "    avg_loss = total_loss / len(train_loader)\n",
    "    return avg_loss, accuracy\n",
    "\n",
    "# 검증 함수 진행 과정\n",
    "def validate(model, val_loader, criterion):\n",
    "    model.eval()     # 평가 모드로 설정\n",
    "    total_loss = 0   # 정확도 확인\n",
    "    correct = 0      \n",
    "    total = 0\n",
    "\n",
    "    with torch.no_grad():  # 그래디언트 계산 비활성화\n",
    "        for images, labels in val_loader:\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "\n",
    "            # 순전파 (Forward)\n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, labels)\n",
    "\n",
    "            # 손실과 정확도 계산\n",
    "            total_loss += loss.item()\n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "            total += labels.size(0)\n",
    "\n",
    "    accuracy = 100 * correct / total\n",
    "    avg_loss = total_loss / len(val_loader)\n",
    "    return avg_loss, accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "429b437b-d4a5-442e-8d84-9521c2e9d4a5",
   "metadata": {},
   "source": [
    "---\n",
    "### 모델 설정 [(model_definitions.py)](./model_definitions.py)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db06f741-9314-4871-a1c9-7dfbd24cc412",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 모델 import\n",
    "from model_definitions import SimpleNN\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchvision\n",
    "\n",
    "num_categories = len(actual_category)\n",
    "\n",
    "# 모델 초기화\n",
    "model = SimpleNN(input_size=image_width*image_height*image_RGB, num_classes=num_categories)\n",
    "                           \n",
    "# 가중치 초기화 함수 정의\n",
    "def initialize_weights(m):\n",
    "    if isinstance(m, nn.Linear):\n",
    "        nn.init.xavier_uniform_(m.weight)\n",
    "        nn.init.zeros_(m.bias)\n",
    "\n",
    "# 모델 가중치 초기화\n",
    "model.apply(initialize_weights)\n",
    "\n",
    "# 손실 함수 및 옵티마이저 설정\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "# 학습률 스케줄러 추가 (선택)\n",
    "scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=10, gamma=0.1)\n",
    "\n",
    "# 장치 설정\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = model.to(device)\n",
    "# 하드웨어 메시지 출력\n",
    "if device.type == \"cuda\":\n",
    "    print(\"cuda 이용\")\n",
    "else:\n",
    "    print(\"cpu 이용\")\n",
    "    \n",
    "# 모델 요약 출력\n",
    "print(model)\n",
    "print(f\"Total parameters: {sum(p.numel() for p in model.parameters() if p.requires_grad)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7c05b53-bda4-4225-b89c-3ea0a2e82ec2",
   "metadata": {},
   "source": [
    "---\n",
    "### **훈련시작**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a90011b-d2af-4359-903c-1c1e17a4efdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 학습 및 검증 루프\n",
    "# epochs 수 만큼 훈현 반복\n",
    "for epoch in range(epochs):\n",
    "    train_loss, train_acc = train_one_epoch(model, train_loader, optimizer, criterion)\n",
    "    val_loss, val_acc = validate(model, val_loader, criterion)\n",
    "\n",
    "    print(f'Epoch [{epoch+1}/{epochs}] '\n",
    "          f'Train Loss: {train_loss:.4f}, Train Accuracy: {train_acc:.2f}% | '\n",
    "          f'Val Loss: {val_loss:.4f}, Val Accuracy: {val_acc:.2f}%')\n",
    "    print(\"-\" * 30)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57144dc0-ac5c-4c3f-982b-c834f6888017",
   "metadata": {},
   "source": [
    "---\n",
    "### 검증 용 샘플 확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df313e0f-e25f-4f44-b19e-97acf9eaf577",
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import display\n",
    "from PIL import Image\n",
    "\n",
    "# Validation 단계에서 샘플 출력 추가\n",
    "sample_display_count = 3  # 출력할 샘플 수\n",
    "\n",
    "# 샘플 검증 함수 정의\n",
    "def validate_samples_with_accuracy(model, val_loader, categories, sample_display_count=5):\n",
    "    \"\"\"\n",
    "    모델을 사용하여 검증 데이터의 샘플을 출력하고 예측 결과와 정확도를 표시.\n",
    "\n",
    "    Args:\n",
    "        model (torch.nn.Module): 학습된 PyTorch 모델\n",
    "        val_loader (DataLoader): 검증 데이터 로더\n",
    "        class_names (list): 클래스 이름 리스트\n",
    "        sample_display_count (int): 출력할 샘플 수\n",
    "    \"\"\"\n",
    "    model.eval()          # 모델을 평가 모드로 전환\n",
    "    sample_displayed = 0  # 출력된 샘플 수를 추적\n",
    "\n",
    "    # Reverse transformation to display original image\n",
    "    reverse_transform = transforms.Compose([\n",
    "        # Normalize를 역으로 적용하여 원본 이미지 복원\n",
    "        transforms.Normalize(mean=[-0.485 / 0.229, -0.456 / 0.224, -0.406 / 0.225], \n",
    "                             std=[1 / 0.229, 1 / 0.224, 1 / 0.225]),\n",
    "        # 텐서를 PIL 이미지로 변환\n",
    "        transforms.ToPILImage()\n",
    "    ])\n",
    "\n",
    "    with torch.no_grad():  # 그래디언트 계산 비활성화 (평가 모드에 적합)\n",
    "        for images, labels in val_loader:\n",
    "            # 검증 데이터 이미지와 라벨을 장치로 이동\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "\n",
    "            # 모델 예측 수행\n",
    "            outputs = model(images)                                      # 모델의 forward 메서드 호출\n",
    "            probabilities = torch.nn.functional.softmax(outputs, dim=1)  # 각 클래스에 대한 확률 계산\n",
    "            _, predicted = torch.max(outputs, 1)                         # 가장 높은 확률의 클래스 인덱스 추출\n",
    "\n",
    "            for i in range(images.size(0)):                              # 현재 배치의 모든 샘플을 순회\n",
    "                if sample_displayed >= sample_display_count:             # 출력할 샘플 수를 초과하면 종료\n",
    "                    return\n",
    "\n",
    "                # 원본 이미지 복원\n",
    "                original_image = reverse_transform(images[i].cpu())      # CPU로 이동 후 변환\n",
    "\n",
    "                # 원본 크기로 이미지를 유지 (height, width 순으로 전달 필요)\n",
    "                original_image = original_image.resize((images.size(2), images.size(3)))\n",
    "\n",
    "                # 예측 결과와 확률 계산\n",
    "                pred_class = categories[predicted[i].item()]  # 예측된 클래스 이름\n",
    "                true_class = categories[labels[i].item()]     # 실제 클래스 이름\n",
    "                pred_confidence = probabilities[i][predicted[i].item()] * 100  # 예측값 확률 (%)\n",
    "\n",
    "                # 이미지 출력 및 예측 정보 표시\n",
    "                display(original_image)  # IPython.display를 통해 이미지 출력\n",
    "                print(f\"True: {true_class}, Pred: {pred_class} ({pred_confidence:.2f}%)\")\n",
    "                if true_class != pred_class:\n",
    "                    print(\"Test Fail\")\n",
    "\n",
    "                sample_displayed += 1  # 출력된 샘플 수 증가\n",
    "\n",
    "# 검증 데이터에서 샘플 출력\n",
    "validate_samples_with_accuracy(model, val_loader, actual_category, sample_display_count)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af3a04ab-82cf-4226-9680-41cda55b69b8",
   "metadata": {},
   "source": [
    "---\n",
    "### **모델 저장**|"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72ab50d8-678a-4748-adeb-d6810e7b07d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 모델 저장\n",
    "torch.save(model,model_name)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
